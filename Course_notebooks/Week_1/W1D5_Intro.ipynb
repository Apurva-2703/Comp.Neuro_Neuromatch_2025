{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "tjIMJjp1NrCp",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esmjlgLiN1jP"
      },
      "source": [
        "# Reflection\n",
        "üß† Key Concepts\n",
        "\n",
        "üîÑ Encoding vs. Decoding Models\n",
        "* Encoding models predict neural activity from stimulus features (e.g., pixels ‚Üí neural response). Useful for understanding what kind of input the brain area is sensitive to.\n",
        "\n",
        "* Decoding models predict stimulus features or behavioral variables from brain activity (e.g., neural response ‚Üí stimulus category). Helps measure how much information is present in a brain area.\n",
        "\n",
        "üîç Representational Similarity Analysis (RSA)\n",
        "* RSA compares the similarity structure of patterns in neural data and model activations. If the model and brain show similar similarity structures across stimuli, they may represent the world in a similar way.\n",
        "\n",
        "üß± Convolutional Neural Networks (CNNs)\n",
        "* A CNN is an artificial neural network structured with convolutional layers that act as feature detectors.\n",
        "  * Each convolutional layer applies a set of filters (kernels) that scan over the input using a sliding window, creating feature maps.\n",
        "\n",
        "    * Example analogy: A 3√ó3 filter moving over a 5√ó5 image, like a flashlight scanning tiles.\n",
        "\n",
        "  * As you go deeper into the network, receptive fields become larger and more abstract:\n",
        "\n",
        "    * Early layers detect edges, textures\n",
        "\n",
        "    * Deeper layers detect objects, faces, scenes\n",
        "\n",
        "üîÅ Backpropagation\n",
        "* A method for training neural networks by minimizing the loss function (e.g., mean squared error).\n",
        "\n",
        "* Calculates how much each weight in the network contributed to the error, and updates the weights using gradient descent.\n",
        "\n",
        "* This learning process is similar to synaptic plasticity in biological neurons.\n",
        "\n",
        "üß† Discrepancy Maps & Artificial Receptive Fields\n",
        "Discrepancy mapping involves masking different regions of an image to see which part is most important for a unit‚Äôs activation.\n",
        "\n",
        "* Averaging these across many images shows a reconstructed receptive field for that unit.\n",
        "\n",
        "* Earlier layers ‚Üí simple shapes; deeper layers ‚Üí complex, holistic object representations.\n",
        "\n",
        "üß∞ Vocabulary\n",
        "\n",
        "Deep Learning\n",
        "Convolution\n",
        "Convolutional Layer\n",
        "Backpropagation\n",
        "Activation Function\tNonlinear transformation\n",
        "PyTorch\n",
        "AlexNet\n",
        "Network Plasticity\n",
        "\n",
        "üí° Fun Facts / Insightful Connections\n",
        "- AlexNet revolutionized computer vision by using ReLUs, dropout, and GPUs‚Äîmajor step in performance on ImageNet.\n",
        "\n",
        "- Hierarchical processing in CNNs mirrors the ventral visual stream (V1 ‚Üí V2 ‚Üí V4 ‚Üí IT), with increasingly abstract representations.\n",
        "\n",
        "- Zhou et al. (2015): Object detectors emerged even in CNNs trained only on scene recognition‚Äîsuggests object representations can arise naturally from training data structure.\n",
        "\n",
        "- Cichy et al. (2016): Used fMRI to compare CNN activity over time to brain activity, showing strong temporal and spatial correspondence between CNN layers and brain regions.\n",
        "\n",
        "Site: netdissect.csail.mit.edu provides interactive tools for visualizing what CNN units are detecting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "f6gf8BwiNrCr",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Overview\n",
        "\n",
        "This day introduces you to some of the applications of deep learning in neuroscience. In the intro, Aude Oliva covers the basics of convolutional neural networks trained to do image recognition and how to compare these artificial neural networks to neural activity in the brain. In the three tutorials, we apply deep learning principles in three key ways they are used in neuroscience: decoding models, encoding models, and representational similarity analysis. In each of the tutorials, we use the same neural activity, which was recorded from the visual cortex of awake mice while the mice were presented with oriented grating stimuli. In Tutorial 1, we start with even simpler neural networks consisting of fully connected linear layers. We introduce non-linear activation functions and how to optimize these deep networks using PyTorch and back-propagation. We optimize the network to decode the presented visual stimulus from the recorded neural activity in the visual cortex. Next, Tutorial 2 introduces convolutional layers, the building blocks of networks for visual tasks. The bonus in that tutorial is to fit an encoding model from visual stimuli to neural activity. Finally, in Tutorial 3, we optimize a convolutional neural network to perform an orientation discrimination task and compare the internal representations of the artificial neural networks to neural activity using a representational similarity analysis technique. In the outro, the caveats of treating neural activity like a deep convolutional neural network are introduced and explored, including approaches to make deep networks more biologically plausible. In the second optional outro, deep learning is used to perform pose estimation of infants and used to make clinical judgments.\n",
        "\n",
        "There is a growing need for data analysis tools as neuroscientists gain the ability to record larger neural populations during more complex behaviors. Deep neural networks can approximate a wide range of non-linear functions. They can be easily fit, allowing them to be flexible model architectures for building decoding and encoding large-scale data models. Generalized linear models (GLMs) were used as decoding and encoding models in W1D3. A model that decodes a variable from neural activity can tell us how much information a brain area contains about that variable. An encoding model is a model from an input variable, like visual stimulus, to neural activity. The encoding model is meant to approximate the same transformation that the brain performs on input variables and therefore help us understand how the brain represents information.\n",
        "\n",
        "The final application of deep neural networks in tutorial 3 is the most common one in neuroscience currently and involves comparing the activity of artificial neural networks to brain activity. Since deep convolutional neural networks are the only types of models that can perform at human accuracy on visual tasks like object recognition, it can often make sense to use them as starting points for comparison with neural data. This comparison can be done at a variety of scales, such as at the population level as in the tutorial or at the level of single neurons and single units in the deep network. This type of research can help answer questions such as what types of datasets and tasks create neural networks that best approximate the brain (e.g., neural taskonomy, in simple words inferring the similarity of task-derived representations from brain activity), and what that means for the architecture and learning rules of the brain. There are other complex tasks that deep networks are trained for that involve learning how to explore environments and determine rewarding stimuli. Stay tuned for more of this in W3D4 Reinforcement Learning."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
