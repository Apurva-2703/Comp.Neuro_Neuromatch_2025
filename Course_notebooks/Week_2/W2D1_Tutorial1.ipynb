{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "n8EKUfpN65vn"
      },
      "source": [
        "# Tutorial 1: Framing the Question\n",
        "\n",
        "**Week 2, Day 1: Modeling Practice**\n",
        "\n",
        "**By Neuromatch Academy**\n",
        "\n",
        "\n",
        "__Content creators:__ Marius 't Hart, Megan Peters, Paul Schrater, Gunnar Blohm, Konrad Kording, Marius Pachitariu\n",
        "\n",
        "__Content reviewers:__ Eric DeWitt, Tara van Viegen, Marius Pachitariu\n",
        "\n",
        "__Production editors:__ Ella Batty, Spiros Chavlis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflection\n",
        "\n",
        "- Learned about the 10 steps to modelling, with a major focus on steps 1-4, which are:\n",
        "  * phenomenon/question/goal.\n",
        "  * conducting a literature review.\n",
        "  * finding model ingredients.\n",
        "  * formulating a mathematically defined hypothesis.\n",
        "\n",
        "- Two types of models:\n",
        "  * Computational model = try to develop an explanation or implement hypothesis. Helps with mechanistic explanations.\n",
        "  * Data-driven model = tests the computational model and raises new questions."
      ],
      "metadata": {
        "id": "VqzhCVA27O1A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ob91Vtyy65vp"
      },
      "source": [
        "---\n",
        "# Tutorial objectives\n",
        "Last week you gained some understanding of what models can buy us in neuroscience. But how do you build a model? Today, we will try to clarify the process of computational modeling, by thinking through the logic of modeling based on your project ideas. We will now work through the 4 first steps of modeling ([Blohm et al., 2019](https://doi.org/10.1523/ENEURO.0352-19.2019)):\n",
        "\n",
        "**Framing the question**\n",
        "\n",
        "1. finding a phenomenon and a question to ask about it\n",
        "2. understanding the state of the art\n",
        "3. determining the basic ingredients\n",
        "4. formulating specific, mathematically defined hypotheses\n",
        "\n",
        "### Demos\n",
        "We will demo the modeling process to you based on the train illusion. In parallel to the computational model, you will develop questions and hypotheses for a data analysis project based on the same phenomenon. This will be done during “Think!” sections.\n",
        "\n",
        "Enjoy!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {},
        "id": "vu2jggC865vr"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for random distributions:\n",
        "from scipy.stats import norm, poisson\n",
        "\n",
        "# for logistic regression:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "woxWtZ_E65vr"
      },
      "outputs": [],
      "source": [
        "# @title Figure settings\n",
        "import logging\n",
        "logging.getLogger('matplotlib.font_manager').disabled = True\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "MPksjWp365vs"
      },
      "outputs": [],
      "source": [
        "# @title Plotting Functions\n",
        "\n",
        "def rasterplot(spikes,movement,trial):\n",
        "\n",
        "  [movements, trials, neurons, timepoints] = np.shape(spikes)\n",
        "\n",
        "  trial_spikes = spikes[movement,trial, :, :]\n",
        "\n",
        "  trial_events = [((trial_spikes[x,:] > 0).nonzero()[0]-150)/100 for x in range(neurons)]\n",
        "\n",
        "  plt.figure()\n",
        "  dt=1/100\n",
        "  plt.eventplot(trial_events, linewidths=1);\n",
        "  plt.title('movement: %d - trial: %d'%(movement, trial))\n",
        "  plt.ylabel('neuron')\n",
        "  plt.xlabel('time [s]')\n",
        "  plt.show()\n",
        "\n",
        "def plotCrossValAccuracies(accuracies):\n",
        "  f, ax = plt.subplots(figsize=(8, 3))\n",
        "  ax.boxplot(accuracies, vert=False, widths=.7)\n",
        "  ax.scatter(accuracies, np.ones(8))\n",
        "  ax.set(xlabel=\"Accuracy\", yticks=[],\n",
        "         title=f\"Average test accuracy: {accuracies.mean():.2%}\")\n",
        "  ax.spines[\"left\"].set_visible(False)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "sdS6SXhj65vt"
      },
      "outputs": [],
      "source": [
        "# @title Generate Data\n",
        "\n",
        "def generateSpikeTrains():\n",
        "\n",
        "  gain = 2\n",
        "  neurons = 50\n",
        "  movements = [0, 1, 2]\n",
        "  repetitions = 800\n",
        "\n",
        "  np.random.seed(37)\n",
        "\n",
        "  # set up the basic parameters:\n",
        "  dt = 1/100\n",
        "  start, stop = -1.5, 1.5\n",
        "  t = np.arange(start, stop+dt, dt)  # a time interval\n",
        "  Velocity_sigma = 0.5  # std dev of the velocity profile\n",
        "  Velocity_Profile = norm.pdf(t, 0, Velocity_sigma)/norm.pdf(0, 0, Velocity_sigma)  # The Gaussian velocity profile, normalized to a peak of 1\n",
        "\n",
        "  # set up the neuron properties:\n",
        "  Gains = np.random.rand(neurons) * gain  # random sensitivity between 0 and `gain`\n",
        "  FRs = (np.random.rand(neurons) * 60 ) - 10  # random base firing rate between -10 and 50\n",
        "\n",
        "  # output matrix will have this shape:\n",
        "  target_shape = [len(movements), repetitions, neurons, len(Velocity_Profile)]\n",
        "\n",
        "  # build matrix for spikes, first, they depend on the velocity profile:\n",
        "  Spikes = np.repeat(Velocity_Profile.reshape([1, 1, 1, len(Velocity_Profile)]),\n",
        "                     len(movements)*repetitions*neurons,axis=2).reshape(target_shape)\n",
        "\n",
        "  # multiplied by gains:\n",
        "  S_gains = np.repeat(np.repeat(Gains.reshape([1, 1, neurons]), len(movements)*repetitions, axis=1).reshape(target_shape[:3]),\n",
        "                      len(Velocity_Profile)).reshape(target_shape)\n",
        "  Spikes = Spikes * S_gains\n",
        "\n",
        "  # and multiplied by the movement:\n",
        "  S_moves = np.repeat( np.array(movements).reshape([len(movements), 1, 1, 1]),\n",
        "                      repetitions*neurons*len(Velocity_Profile), axis=3 ).reshape(target_shape)\n",
        "  Spikes = Spikes * S_moves\n",
        "\n",
        "  # on top of a baseline firing rate:\n",
        "  S_FR = np.repeat(np.repeat(FRs.reshape([1, 1, neurons]),\n",
        "                             len(movements)*repetitions, axis=1).reshape(target_shape[:3]),\n",
        "                   len(Velocity_Profile)).reshape(target_shape)\n",
        "  Spikes = Spikes + S_FR\n",
        "\n",
        "  # can not run the poisson random number generator on input lower than 0:\n",
        "  Spikes = np.where(Spikes < 0, 0, Spikes)\n",
        "\n",
        "  # so far, these were expected firing rates per second, correct for dt:\n",
        "  Spikes = poisson.rvs(Spikes * dt)\n",
        "\n",
        "  return(Spikes)\n",
        "\n",
        "\n",
        "def subsetPerception(spikes):\n",
        "\n",
        "  movements = [0, 1, 2]\n",
        "  split = 400\n",
        "  subset = 40\n",
        "  hwin = 3\n",
        "\n",
        "  [num_movements, repetitions, neurons, timepoints] = np.shape(spikes)\n",
        "\n",
        "  decision = np.zeros([num_movements, repetitions])\n",
        "\n",
        "  # ground truth for logistic regression:\n",
        "  y_train = np.repeat([0, 1, 1],split)\n",
        "  y_test = np.repeat([0, 1, 1],repetitions-split)\n",
        "\n",
        "  m_train = np.repeat(movements, split)\n",
        "  m_test = np.repeat(movements, split)\n",
        "\n",
        "  # reproduce the time points:\n",
        "  dt = 1/100\n",
        "  start, stop = -1.5, 1.5\n",
        "  t = np.arange(start, stop+dt, dt)\n",
        "\n",
        "  w_idx = list( (abs(t) < (hwin*dt)).nonzero()[0] )\n",
        "  w_0 = min(w_idx)\n",
        "  w_1 = max(w_idx)+1  # python...\n",
        "\n",
        "  # get the total spike counts from stationary and movement trials:\n",
        "  spikes_stat = np.sum( spikes[0, :, :, :], axis=2)\n",
        "  spikes_move = np.sum( spikes[1:, :, :, :], axis=3)\n",
        "\n",
        "  train_spikes_stat = spikes_stat[:split, :]\n",
        "  train_spikes_move = spikes_move[:, :split, :].reshape([-1, neurons])\n",
        "\n",
        "  test_spikes_stat = spikes_stat[split:, :]\n",
        "  test_spikes_move = spikes_move[:, split:, :].reshape([-1, neurons])\n",
        "\n",
        "  # data to use to predict y:\n",
        "  x_train = np.concatenate((train_spikes_stat, train_spikes_move))\n",
        "  x_test  = np.concatenate((test_spikes_stat, test_spikes_move))\n",
        "\n",
        "  # this line creates a logistics regression model object, and immediately fits it:\n",
        "  population_model = LogisticRegression(solver='liblinear', random_state=0).fit(x_train, y_train)\n",
        "\n",
        "  # solver, one of: 'liblinear', 'newton-cg', 'lbfgs', 'sag', and 'saga'\n",
        "  # some of those require certain other options\n",
        "  #print(population_model.coef_)       # slope\n",
        "  #print(population_model.intercept_)  # intercept\n",
        "\n",
        "  ground_truth = np.array(population_model.predict(x_test))\n",
        "  ground_truth = ground_truth.reshape([3, -1])\n",
        "\n",
        "  output = {}\n",
        "  output['perception'] = ground_truth\n",
        "  output['spikes'] = spikes[:, split:, :subset, :]\n",
        "\n",
        "  return(output)\n",
        "\n",
        "\n",
        "def getData():\n",
        "\n",
        "  spikes = generateSpikeTrains()\n",
        "\n",
        "  dataset = subsetPerception(spikes=spikes)\n",
        "\n",
        "  return(dataset)\n",
        "\n",
        "\n",
        "dataset = getData()\n",
        "perception = dataset['perception']\n",
        "spikes = dataset['spikes']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ReJm_rnY65vu"
      },
      "source": [
        "----\n",
        "# Step 1: Finding a phenomenon and a question to ask about it\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video 1: Asking a question.\n",
        "\n",
        "Pitfalls:\n",
        "* Vague question\n",
        "* Question is a toolkit or model-first\n",
        "* Precise aspect of phenomenon to model is unclear [solution: literature review?]\n",
        "* No clear goal behind the question\n",
        "*"
      ],
      "metadata": {
        "id": "tXdPtVay87RG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Px42Xb6c65vv"
      },
      "source": [
        "As a reminder, here is what you should discuss and write down:\n",
        "\n",
        "* What exact aspect of this neural with *N* neurons and *M* trials data needs modeling?\n",
        "* Define an evaluation method!\n",
        "  * How will you know your modeling is good?\n",
        "  * E.g., comparison to specific data (quantitative method of comparison?)\n",
        "* Think of an experiment that could test your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "X0fwpuEg65vw"
      },
      "source": [
        "**Note**\n",
        "\n",
        "The hardest part is Step 1. Once that is properly set up, all the others should be easier. **BUT**: often you think that Step 1 is done only to figure out in later steps (anywhere really) that you were not as clear on your question and goal than you thought. Revisiting Step 1 is a frequent necessity. Don't feel bad about it. You can revisit Step 1 later; for now, let's move onto the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "vS3Y1bHV65vw"
      },
      "source": [
        "----\n",
        "# Step 2: Understanding the state of the art & background\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "R_UfNCE065vw"
      },
      "source": [
        "Here you will learn how to do a literature review (**to be done for your project AFTER this tutorial!**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Igr_syjg65vw"
      },
      "source": [
        "----\n",
        "# Step 3: Determining the basic ingredients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pitfalls:\n",
        "\n",
        "* I’m experienced, I don’t need to think about ingredients anymore\n",
        "\n",
        "* I can’t think of any ingredients (stimuli, parameters, controls, measurements?)\n",
        "\n",
        "* I can’t think of any links (= mechanisms) between the inputs and outputs."
      ],
      "metadata": {
        "id": "z88OOwvaHP0D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "rR1vDqki65vx"
      },
      "source": [
        "----\n",
        "# Step 4: Formulating specific, mathematically defined hypotheses\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I don’t need hypotheses, I will just play around with the model\n",
        "* My hypotheses don’t match my question (or vice versa)\n",
        "* I can’t write down a math hypothesis (... means you lack ingredients *or* you have a structural hypothesis - expecting a certain model component to be crucial in explaining the phenomenon)\n"
      ],
      "metadata": {
        "id": "UU4Fcfo3NOIV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "nbltMP0N65vy"
      },
      "source": [
        "If you want to learn more about steps 5-10 of modelling from ([Blohm et al., 2019](https://doi.org/10.1523/ENEURO.0352-19.2019)), you can later read the paper, or check out the optional notebook available [here](https://compneuro.neuromatch.io/projects/modelingsteps/ModelingSteps_5through10.html). However, at the Neuromatch Academy, we would like you to use a new app built specifically to help with projects, the NMA project planner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "4Gni-eqg65vy"
      },
      "source": [
        "----\n",
        "# NMA project planner\n",
        "\n",
        "For the rest of the project time today and until the end of the summer school, you will use an online tool ([here](https://nma-project-planner.vercel.app)) that will help you organize the questions, hypotheses, datasets, methods and other ingredients for the projects. The tool is built on a large language model that takes your answers and compares them to the requirements of the section, then gives you feedback about how well the answers match the requirements and what you can do to improve your score. The fields you complete are persistent on the computer where you complete them, and they can be easily saved/loaded and shared between the group. Start filling out this tool together (one person shares their screen), and then share the saved file with everyone in the group.\n",
        "\n",
        "Note that for NMA we do not consider it important what order you complete the project planner in. For some projects, it might make sense to start with the dataset, since you need to understand this well before you can formulate questions about it. For other types of projects, you might want to start with the question, for example if you plan to make your own model of a phenomenon, like in the train illusion. The only thing that matters is that at the end of the summer school, all sections have been filled, and you have good scores on all sections (7 or above, we won’t check, don’t worry).\n",
        "\n",
        "Watch Konrad tell you more about [the app](https://nma-project-planner.vercel.app) he has built in the video below!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "MLszshXx65v1"
      },
      "source": [
        "----\n",
        "# Summary\n",
        "\n",
        "In this tutorial, we worked through some steps of the process of modeling.\n",
        "\n",
        "- We defined a phenomenon and formulated a question (step 1)\n",
        "- We collected information the state-of-the-art about the topic (step 2)\n",
        "- We determined the basic ingredients (step 3), and used these to formulate a specific mathematically defined hypothesis (step 4)\n",
        "\n",
        "We further introduced the NMA project planner, which will guide you throughout the entire project development over the next two weeks. For the rest of today, you will use the project planner and the additional guidance in the project guide to make progress. Any progress is good progress, on any of the sections in the project planner. Different projects may progress through the sections in a different order, but what matters is that at the end all the sections are filled out. Find the order that works best for you and your team, and revisit each section as often as needed to make a solid overall project plan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "SlzJBBaB65v1"
      },
      "source": [
        "----\n",
        "# Reading\n",
        "Blohm G, Kording KP, Schrater PR (2020). A How-to-Model Guide for Neuroscience. _eNeuro_, 7(1) ENEURO.0352-19.2019. doi: [10.1523/ENEURO.0352-19.2019](https://doi.org/10.1523/ENEURO.0352-19.2019)\n",
        "\n",
        "Kording KP, Blohm G, Schrater P, Kay K (2020). Appreciating the variety of goals in computational neuroscience. _Neurons, Behavior, Data Analysis, and Theory_ 3(6). arXiv: [arxiv:2002.03211v1](https://arxiv.org/abs/2002.03211v1), url: [https://nbdt.scholasticahq.com/article/16723-appreciating-the-variety-of-goals-in-computational-neuroscience](https://nbdt.scholasticahq.com/article/16723-appreciating-the-variety-of-goals-in-computational-neuroscience)\n",
        "\n",
        "Schrater PR, Peters MK, Kording KP, Blohm G (2019). Modeling in Neuroscience as a Decision Process. _OSF pre-print_. url: [https://osf.io/w56vt/](https://osf.io/w56vt/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "W2D1_Tutorial1",
      "provenance": []
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}